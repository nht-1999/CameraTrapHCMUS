{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cf782c-b24a-4efe-a723-0eccef99c158",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7adef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"import os\\nimport numpy as np\\nimport pandas as pd\\nfrom collections import Counter\\nfrom sklearn.model_selection import train_test_split\\nimport joblib\\nimport json\\nimport cv2\\nfrom time import time\\nimport threading\\nimport math\\nimport pickle\\nfrom glob import glob\\nfrom time import time\\n\\n# coding=utf-8\\nfrom __future__ import absolute_import, print_function\\nimport torch\\nfrom sklearn import metrics\\n\\nfrom DataSet.dataset import get_iwildcam_loader, data_prefetcher\\nfrom Utils.train_utils import cross_entropy,focal_loss, get_optimizer\\nfrom Utils.train_utils import mixup_data, mixup_criterion\\nfrom Models.model_factory import create_model\\n\\nimport warnings\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nos.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\\nos.environ['CUDA_VISIBLE_DEVICES'] = \\\"0\\\"\\n\\ndevice = torch.device(\\\"cuda:0\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n%load_ext nb_black\\n\\nprint('device:', device)\";\n",
       "                var nbb_formatted_code = \"import os\\nimport numpy as np\\nimport pandas as pd\\nfrom collections import Counter\\nfrom sklearn.model_selection import train_test_split\\nimport joblib\\nimport json\\nimport cv2\\nfrom time import time\\nimport threading\\nimport math\\nimport pickle\\nfrom glob import glob\\nfrom time import time\\n\\n# coding=utf-8\\nfrom __future__ import absolute_import, print_function\\nimport torch\\nfrom sklearn import metrics\\n\\nfrom DataSet.dataset import get_iwildcam_loader, data_prefetcher\\nfrom Utils.train_utils import cross_entropy, focal_loss, get_optimizer\\nfrom Utils.train_utils import mixup_data, mixup_criterion\\nfrom Models.model_factory import create_model\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nos.environ[\\\"CUDA_DEVICE_ORDER\\\"] = \\\"PCI_BUS_ID\\\"\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"0\\\"\\n\\ndevice = torch.device(\\\"cuda:0\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n%load_ext nb_black\\n\\nprint(\\\"device:\\\", device)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import json\n",
    "import cv2\n",
    "from time import time\n",
    "import threading\n",
    "import math\n",
    "import pickle\n",
    "from glob import glob\n",
    "from time import time\n",
    "\n",
    "# coding=utf-8\n",
    "from __future__ import absolute_import, print_function\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "\n",
    "from DataSet.dataset import get_iwildcam_loader, data_prefetcher\n",
    "from Utils.train_utils import cross_entropy,focal_loss, get_optimizer\n",
    "from Utils.train_utils import mixup_data, mixup_criterion\n",
    "from Models.model_factory import create_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "%load_ext nb_black\n",
    "\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feab532",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare data\n",
    "\n",
    "1. rewrite_train_data_json => đổi anotation dạng json sang csv (CTT và iN) => `data/train_file.csv`, `data/test_file.csv`\n",
    "2. `data/train_file.csv` sau khi  => dev location = 46, train location != 4at6, lấy các cột date_captured, category_id, file_name (đổi đường dẫn cho đúng), rights_holder, id, width, height, location (k có thì -1) => `train_file.csv`, `dev_file.csv`\n",
    "3. `data/test_file.csv` lấy các cột category_id, file_name => `test_file.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b19320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"DATASET={'CCT':'iWildCam_2019_CCT','iNat':'iWildCam_2019_iNat_Idaho','IDFG':'iWildCam_IDFG'} #_images_small\\nDATA_DIR='./data/'\\nANNOTATION_DIR =DATA_DIR+ 'iWildCam_2019_Annotations/'\";\n",
       "                var nbb_formatted_code = \"DATASET = {\\n    \\\"CCT\\\": \\\"iWildCam_2019_CCT\\\",\\n    \\\"iNat\\\": \\\"iWildCam_2019_iNat_Idaho\\\",\\n    \\\"IDFG\\\": \\\"iWildCam_IDFG\\\",\\n}  # _images_small\\nDATA_DIR = \\\"./data/\\\"\\nANNOTATION_DIR = DATA_DIR + \\\"iWildCam_2019_Annotations/\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATASET={'CCT':'iWildCam_2019_CCT','iNat':'iWildCam_2019_iNat_Idaho','IDFG':'iWildCam_IDFG'} #_images_small\n",
    "DATA_DIR='./data/'\n",
    "ANNOTATION_DIR =DATA_DIR+ 'iWildCam_2019_Annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6123492a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def rewrite_train_data_json(dataset='CCT'):\\n\\tjson_path=ANNOTATION_DIR+DATASET[dataset]+'.json'\\n\\n\\tjson_data = json.load(open(json_path,'r'))\\n\\timages = json_data['images']\\n\\tannotations = json_data['annotations']\\n\\tcsv_data={'category_id':[],'date_captured':[],'id':[],'file_name':[],\\n\\t          'rights_holder':[],'width':[],'height':[],'location':[]}\\n\\tprint('len of  data:',dataset,len(images))\\n\\tfor ii,(img, annot) in enumerate(zip(images,annotations)):\\n\\t\\tif img['id'] != annot['image_id']:\\n\\t\\t\\tprint('there are some error in',ii,img['id'],annot['image_id'])\\n\\t\\tif 'date_captured' in img:\\n\\t\\t\\tdate=img['date_captured']\\n\\t\\telif 'datetime' in img:\\n\\t\\t\\tdate = img['datetime']\\n\\t\\telse:\\n\\t\\t\\tdate = json_data['info']['date_created']\\n\\t\\tcsv_data['date_captured'] += [date]\\n\\t\\tcsv_data['category_id'] += [annot['category_id']]\\n\\t\\tcsv_data['file_name'] += [img['file_name']]\\n\\t\\tcsv_data['rights_holder'] += [img['rights_holder']]\\n\\t\\tcsv_data['id'] += [img['id']]\\n\\t\\tcsv_data['width'] += [img['width']]\\n\\t\\tcsv_data['height'] += [img['height']]\\n\\t\\tif 'location' in img:\\n\\t\\t\\tlocat = img['location']\\n\\t\\telse:\\n\\t\\t\\tlocat=-1\\n\\t\\tcsv_data['location'] += [locat]\\n\\n\\n\\tcsv_data = pd.DataFrame(csv_data)\\n\\tcsv_data.to_csv(ANNOTATION_DIR+DATASET[dataset]+'.csv',index=False)\\n\\n\\ndef split_train_dev(CCT=True,iNat=True):\\n\\tcolumns=['category_id','date_captured','id','file_name',\\n\\t          'rights_holder','width','height','location']\\n\\ttrain=pd.DataFrame()\\n\\tif CCT:\\n\\t\\ttemp=pd.read_csv(ANNOTATION_DIR+DATASET['CCT']+'.csv')[columns]\\n\\t\\ttemp['dataset'] = 'CCT'\\n\\t\\ttemp['file_name'] = temp['file_name'].map(lambda x:'iWildCam_2019_CCT_images_small/'+x)\\n\\t\\tprint('use CCT data',temp.shape)\\n\\t\\ttrain=pd.concat([train,temp])\\n\\n\\tif iNat:\\n\\t\\ttemp=pd.read_csv(ANNOTATION_DIR+DATASET['iNat']+'.csv')[columns]\\n\\t\\ttemp['dataset'] = 'iNat'\\n\\t\\ttemp['file_name'] = temp['file_name'].map(lambda x: 'iWildCam_2019_iNat_Idaho/' + x)\\n\\t\\tprint('use iNat data',temp.shape)\\n\\t\\ttrain=pd.concat([train,temp])\\n\\n\\n\\tprint('train shape',train.shape)\\n\\t#train=train.sample(frac=1,random_state=0).reset_index(drop=True)\\n\\n\\tdev_file = train[train['location'] == 46]  # 46\\n\\ttrain_file = train[train['location'] != 46]\\n\\n\\n\\ttrain_file.to_csv(DATA_DIR+'train_file.csv',index=False)\\n\\tdev_file.to_csv(DATA_DIR+'dev_file.csv',index=False)\\n\\n\\tprint('category ratio for train data:')\\n\\tcnt = Counter(train_file['category_id'].values)\\n\\tL = len(train_file)\\n\\tfor ii in range(23):\\n\\t\\tprint(ii, cnt[ii], cnt[ii] / L)\\n\\n\\tprint('category ratio for dev data:')\\n\\tcnt = Counter(dev_file['category_id'].values)\\n\\tL = len(dev_file)\\n\\tfor ii in range(23):\\n\\t\\tprint(ii, cnt[ii], cnt[ii] / L)\\n\\n\\ndef save_test():\\n\\tcolumns=['date_captured','id','file_name',\\n\\t          'rights_holder','width','height','location']\\n\\ttest = pd.read_csv(DATA_DIR+'test.csv')[columns]\\n\\ttest['dataset'] = 'test'\\n\\ttest['category_id'] = -1\\n\\ttest['file_name'] = test['file_name'].map(lambda x:'test_images/'+x)\\n\\tprint('test shape',test.shape) #153730\\n\\n\\ttest.to_csv(DATA_DIR+'test_file.csv',index=False)\\n\\nfull_data_dir='data/raw_data/iWildCam_2019_IDFG/iWildCam_IDFG_images/'\\ndef get_test_orig_size_split(test_file,name=0):\\n\\tname=str(name)\\n\\tprint('get_test_orig_size_split for thread',name,test_file.shape)\\n\\tfile_names= test_file['file_name'].values\\n\\twidth,height=[],[]\\n\\tt1=time()\\n\\tfor ii,fname in enumerate(file_names):\\n\\t\\tmod_name =full_data_dir + fname.split('/')[-1]\\n\\t\\timage = cv2.imread(mod_name)\\n\\t\\ts = image.shape\\n\\t\\t#imageHeight = s[0]\\n\\t\\t#imageWidth = s[1]\\n\\t\\twidth.append(s[0])\\n\\t\\theight.append(s[1])\\n\\t\\tif ii%100==0:\\n\\t\\t\\tprint('threads %s, index %d, time-cost %f min'%(name,ii,(time()-t1)/60))\\n\\t\\tif ii % 1000 == 0:\\n\\t\\t\\tjoblib.dump([ii,width,height],DATA_DIR+'raw_data/test_size_temp_{}.pkl'.format(name))\\n\\ttest_file['width']=width\\n\\ttest_file['height'] = height\\n\\tprint(name,'test shape',test_file.shape) #153730\\n\\n\\ttest_file.to_csv(DATA_DIR+'raw_data/test_file_orig_{}.csv'.format(name),index=False)\\n\\ndef get_test_size_multi_thread(thread_num=1):\\n\\ttest_file = pd.read_csv(DATA_DIR+'test_file.csv')\\n\\ttest_file['small_width']=test_file['width']\\n\\ttest_file['small_height'] = test_file['height']\\n\\tchunk=math.ceil(len(test_file)/thread_num)\\n\\tthread_list=[]\\n\\tfor ii in range(thread_num):\\n\\t\\tsup_file=test_file.iloc[ii*chunk:(ii+1)*chunk]\\n\\t\\tthr=threading.Thread(target=get_test_orig_size_split,args=(sup_file,ii))\\n\\t\\tthread_list.append(thr)\\n\\tfor t in thread_list:\\n\\t\\tt.setDaemon(True)\\n\\t\\tt.start()\\n\\tfor t in thread_list:\\n\\t\\tt.join()\\n\\ndef merge_test_size_file():\\n\\tdata=pd.DataFrame()\\n\\tfor name in range(10):\\n\\t\\tdata_path=DATA_DIR + 'raw_data/test_file_orig_{}.csv'.format(str(name))\\n\\t\\ttemp=pd.read_csv(data_path)\\n\\t\\tdata=pd.concat([data,temp])\\n\\t\\tprint(name,data.shape)\\n\\n\\tdata.to_csv(DATA_DIR + 'raw_data/test_file.csv',index=False)\";\n",
       "                var nbb_formatted_code = \"def rewrite_train_data_json(dataset=\\\"CCT\\\"):\\n    json_path = ANNOTATION_DIR + DATASET[dataset] + \\\".json\\\"\\n\\n    json_data = json.load(open(json_path, \\\"r\\\"))\\n    images = json_data[\\\"images\\\"]\\n    annotations = json_data[\\\"annotations\\\"]\\n    csv_data = {\\n        \\\"category_id\\\": [],\\n        \\\"date_captured\\\": [],\\n        \\\"id\\\": [],\\n        \\\"file_name\\\": [],\\n        \\\"rights_holder\\\": [],\\n        \\\"width\\\": [],\\n        \\\"height\\\": [],\\n        \\\"location\\\": [],\\n    }\\n    print(\\\"len of  data:\\\", dataset, len(images))\\n    for ii, (img, annot) in enumerate(zip(images, annotations)):\\n        if img[\\\"id\\\"] != annot[\\\"image_id\\\"]:\\n            print(\\\"there are some error in\\\", ii, img[\\\"id\\\"], annot[\\\"image_id\\\"])\\n        if \\\"date_captured\\\" in img:\\n            date = img[\\\"date_captured\\\"]\\n        elif \\\"datetime\\\" in img:\\n            date = img[\\\"datetime\\\"]\\n        else:\\n            date = json_data[\\\"info\\\"][\\\"date_created\\\"]\\n        csv_data[\\\"date_captured\\\"] += [date]\\n        csv_data[\\\"category_id\\\"] += [annot[\\\"category_id\\\"]]\\n        csv_data[\\\"file_name\\\"] += [img[\\\"file_name\\\"]]\\n        csv_data[\\\"rights_holder\\\"] += [img[\\\"rights_holder\\\"]]\\n        csv_data[\\\"id\\\"] += [img[\\\"id\\\"]]\\n        csv_data[\\\"width\\\"] += [img[\\\"width\\\"]]\\n        csv_data[\\\"height\\\"] += [img[\\\"height\\\"]]\\n        if \\\"location\\\" in img:\\n            locat = img[\\\"location\\\"]\\n        else:\\n            locat = -1\\n        csv_data[\\\"location\\\"] += [locat]\\n\\n    csv_data = pd.DataFrame(csv_data)\\n    csv_data.to_csv(ANNOTATION_DIR + DATASET[dataset] + \\\".csv\\\", index=False)\\n\\n\\ndef split_train_dev(CCT=True, iNat=True):\\n    columns = [\\n        \\\"category_id\\\",\\n        \\\"date_captured\\\",\\n        \\\"id\\\",\\n        \\\"file_name\\\",\\n        \\\"rights_holder\\\",\\n        \\\"width\\\",\\n        \\\"height\\\",\\n        \\\"location\\\",\\n    ]\\n    train = pd.DataFrame()\\n    if CCT:\\n        temp = pd.read_csv(ANNOTATION_DIR + DATASET[\\\"CCT\\\"] + \\\".csv\\\")[columns]\\n        temp[\\\"dataset\\\"] = \\\"CCT\\\"\\n        temp[\\\"file_name\\\"] = temp[\\\"file_name\\\"].map(\\n            lambda x: \\\"iWildCam_2019_CCT_images_small/\\\" + x\\n        )\\n        print(\\\"use CCT data\\\", temp.shape)\\n        train = pd.concat([train, temp])\\n\\n    if iNat:\\n        temp = pd.read_csv(ANNOTATION_DIR + DATASET[\\\"iNat\\\"] + \\\".csv\\\")[columns]\\n        temp[\\\"dataset\\\"] = \\\"iNat\\\"\\n        temp[\\\"file_name\\\"] = temp[\\\"file_name\\\"].map(\\n            lambda x: \\\"iWildCam_2019_iNat_Idaho/\\\" + x\\n        )\\n        print(\\\"use iNat data\\\", temp.shape)\\n        train = pd.concat([train, temp])\\n\\n    print(\\\"train shape\\\", train.shape)\\n    # train=train.sample(frac=1,random_state=0).reset_index(drop=True)\\n\\n    dev_file = train[train[\\\"location\\\"] == 46]  # 46\\n    train_file = train[train[\\\"location\\\"] != 46]\\n\\n    train_file.to_csv(DATA_DIR + \\\"train_file.csv\\\", index=False)\\n    dev_file.to_csv(DATA_DIR + \\\"dev_file.csv\\\", index=False)\\n\\n    print(\\\"category ratio for train data:\\\")\\n    cnt = Counter(train_file[\\\"category_id\\\"].values)\\n    L = len(train_file)\\n    for ii in range(23):\\n        print(ii, cnt[ii], cnt[ii] / L)\\n\\n    print(\\\"category ratio for dev data:\\\")\\n    cnt = Counter(dev_file[\\\"category_id\\\"].values)\\n    L = len(dev_file)\\n    for ii in range(23):\\n        print(ii, cnt[ii], cnt[ii] / L)\\n\\n\\ndef save_test():\\n    columns = [\\n        \\\"date_captured\\\",\\n        \\\"id\\\",\\n        \\\"file_name\\\",\\n        \\\"rights_holder\\\",\\n        \\\"width\\\",\\n        \\\"height\\\",\\n        \\\"location\\\",\\n    ]\\n    test = pd.read_csv(DATA_DIR + \\\"test.csv\\\")[columns]\\n    test[\\\"dataset\\\"] = \\\"test\\\"\\n    test[\\\"category_id\\\"] = -1\\n    test[\\\"file_name\\\"] = test[\\\"file_name\\\"].map(lambda x: \\\"test_images/\\\" + x)\\n    print(\\\"test shape\\\", test.shape)  # 153730\\n\\n    test.to_csv(DATA_DIR + \\\"test_file.csv\\\", index=False)\\n\\n\\nfull_data_dir = \\\"data/raw_data/iWildCam_2019_IDFG/iWildCam_IDFG_images/\\\"\\n\\n\\ndef get_test_orig_size_split(test_file, name=0):\\n    name = str(name)\\n    print(\\\"get_test_orig_size_split for thread\\\", name, test_file.shape)\\n    file_names = test_file[\\\"file_name\\\"].values\\n    width, height = [], []\\n    t1 = time()\\n    for ii, fname in enumerate(file_names):\\n        mod_name = full_data_dir + fname.split(\\\"/\\\")[-1]\\n        image = cv2.imread(mod_name)\\n        s = image.shape\\n        # imageHeight = s[0]\\n        # imageWidth = s[1]\\n        width.append(s[0])\\n        height.append(s[1])\\n        if ii % 100 == 0:\\n            print(\\n                \\\"threads %s, index %d, time-cost %f min\\\"\\n                % (name, ii, (time() - t1) / 60)\\n            )\\n        if ii % 1000 == 0:\\n            joblib.dump(\\n                [ii, width, height],\\n                DATA_DIR + \\\"raw_data/test_size_temp_{}.pkl\\\".format(name),\\n            )\\n    test_file[\\\"width\\\"] = width\\n    test_file[\\\"height\\\"] = height\\n    print(name, \\\"test shape\\\", test_file.shape)  # 153730\\n\\n    test_file.to_csv(\\n        DATA_DIR + \\\"raw_data/test_file_orig_{}.csv\\\".format(name), index=False\\n    )\\n\\n\\ndef get_test_size_multi_thread(thread_num=1):\\n    test_file = pd.read_csv(DATA_DIR + \\\"test_file.csv\\\")\\n    test_file[\\\"small_width\\\"] = test_file[\\\"width\\\"]\\n    test_file[\\\"small_height\\\"] = test_file[\\\"height\\\"]\\n    chunk = math.ceil(len(test_file) / thread_num)\\n    thread_list = []\\n    for ii in range(thread_num):\\n        sup_file = test_file.iloc[ii * chunk : (ii + 1) * chunk]\\n        thr = threading.Thread(target=get_test_orig_size_split, args=(sup_file, ii))\\n        thread_list.append(thr)\\n    for t in thread_list:\\n        t.setDaemon(True)\\n        t.start()\\n    for t in thread_list:\\n        t.join()\\n\\n\\ndef merge_test_size_file():\\n    data = pd.DataFrame()\\n    for name in range(10):\\n        data_path = DATA_DIR + \\\"raw_data/test_file_orig_{}.csv\\\".format(str(name))\\n        temp = pd.read_csv(data_path)\\n        data = pd.concat([data, temp])\\n        print(name, data.shape)\\n\\n    data.to_csv(DATA_DIR + \\\"raw_data/test_file.csv\\\", index=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rewrite_train_data_json(dataset='CCT'):\n",
    "\tjson_path=ANNOTATION_DIR+DATASET[dataset]+'.json'\n",
    "\n",
    "\tjson_data = json.load(open(json_path,'r'))\n",
    "\timages = json_data['images']\n",
    "\tannotations = json_data['annotations']\n",
    "\tcsv_data={'category_id':[],'date_captured':[],'id':[],'file_name':[],\n",
    "\t          'rights_holder':[],'width':[],'height':[],'location':[]}\n",
    "\tprint('len of  data:',dataset,len(images))\n",
    "\tfor ii,(img, annot) in enumerate(zip(images,annotations)):\n",
    "\t\tif img['id'] != annot['image_id']:\n",
    "\t\t\tprint('there are some error in',ii,img['id'],annot['image_id'])\n",
    "\t\tif 'date_captured' in img:\n",
    "\t\t\tdate=img['date_captured']\n",
    "\t\telif 'datetime' in img:\n",
    "\t\t\tdate = img['datetime']\n",
    "\t\telse:\n",
    "\t\t\tdate = json_data['info']['date_created']\n",
    "\t\tcsv_data['date_captured'] += [date]\n",
    "\t\tcsv_data['category_id'] += [annot['category_id']]\n",
    "\t\tcsv_data['file_name'] += [img['file_name']]\n",
    "\t\tcsv_data['rights_holder'] += [img['rights_holder']]\n",
    "\t\tcsv_data['id'] += [img['id']]\n",
    "\t\tcsv_data['width'] += [img['width']]\n",
    "\t\tcsv_data['height'] += [img['height']]\n",
    "\t\tif 'location' in img:\n",
    "\t\t\tlocat = img['location']\n",
    "\t\telse:\n",
    "\t\t\tlocat=-1\n",
    "\t\tcsv_data['location'] += [locat]\n",
    "\n",
    "\n",
    "\tcsv_data = pd.DataFrame(csv_data)\n",
    "\tcsv_data.to_csv(ANNOTATION_DIR+DATASET[dataset]+'.csv',index=False)\n",
    "\n",
    "\n",
    "def split_train_dev(CCT=True,iNat=True):\n",
    "\tcolumns=['category_id','date_captured','id','file_name',\n",
    "\t          'rights_holder','width','height','location']\n",
    "\ttrain=pd.DataFrame()\n",
    "\tif CCT:\n",
    "\t\ttemp=pd.read_csv(ANNOTATION_DIR+DATASET['CCT']+'.csv')[columns]\n",
    "\t\ttemp['dataset'] = 'CCT'\n",
    "\t\ttemp['file_name'] = temp['file_name'].map(lambda x:'iWildCam_2019_CCT_images_small/'+x)\n",
    "\t\tprint('use CCT data',temp.shape)\n",
    "\t\ttrain=pd.concat([train,temp])\n",
    "\n",
    "\tif iNat:\n",
    "\t\ttemp=pd.read_csv(ANNOTATION_DIR+DATASET['iNat']+'.csv')[columns]\n",
    "\t\ttemp['dataset'] = 'iNat'\n",
    "\t\ttemp['file_name'] = temp['file_name'].map(lambda x: 'iWildCam_2019_iNat_Idaho/' + x)\n",
    "\t\tprint('use iNat data',temp.shape)\n",
    "\t\ttrain=pd.concat([train,temp])\n",
    "\n",
    "\n",
    "\tprint('train shape',train.shape)\n",
    "\t#train=train.sample(frac=1,random_state=0).reset_index(drop=True)\n",
    "\n",
    "\tdev_file = train[train['location'] == 46]  # 46\n",
    "\ttrain_file = train[train['location'] != 46]\n",
    "\n",
    "\n",
    "\ttrain_file.to_csv(DATA_DIR+'train_file.csv',index=False)\n",
    "\tdev_file.to_csv(DATA_DIR+'dev_file.csv',index=False)\n",
    "\n",
    "\tprint('category ratio for train data:')\n",
    "\tcnt = Counter(train_file['category_id'].values)\n",
    "\tL = len(train_file)\n",
    "\tfor ii in range(23):\n",
    "\t\tprint(ii, cnt[ii], cnt[ii] / L)\n",
    "\n",
    "\tprint('category ratio for dev data:')\n",
    "\tcnt = Counter(dev_file['category_id'].values)\n",
    "\tL = len(dev_file)\n",
    "\tfor ii in range(23):\n",
    "\t\tprint(ii, cnt[ii], cnt[ii] / L)\n",
    "\n",
    "\n",
    "def save_test():\n",
    "\tcolumns=['date_captured','id','file_name',\n",
    "\t          'rights_holder','width','height','location']\n",
    "\ttest = pd.read_csv(DATA_DIR+'test.csv')[columns]\n",
    "\ttest['dataset'] = 'test'\n",
    "\ttest['category_id'] = -1\n",
    "\ttest['file_name'] = test['file_name'].map(lambda x:'test_images/'+x)\n",
    "\tprint('test shape',test.shape) #153730\n",
    "\n",
    "\ttest.to_csv(DATA_DIR+'test_file.csv',index=False)\n",
    "\n",
    "full_data_dir='data/raw_data/iWildCam_2019_IDFG/iWildCam_IDFG_images/'\n",
    "def get_test_orig_size_split(test_file,name=0):\n",
    "\tname=str(name)\n",
    "\tprint('get_test_orig_size_split for thread',name,test_file.shape)\n",
    "\tfile_names= test_file['file_name'].values\n",
    "\twidth,height=[],[]\n",
    "\tt1=time()\n",
    "\tfor ii,fname in enumerate(file_names):\n",
    "\t\tmod_name =full_data_dir + fname.split('/')[-1]\n",
    "\t\timage = cv2.imread(mod_name)\n",
    "\t\ts = image.shape\n",
    "\t\t#imageHeight = s[0]\n",
    "\t\t#imageWidth = s[1]\n",
    "\t\twidth.append(s[0])\n",
    "\t\theight.append(s[1])\n",
    "\t\tif ii%100==0:\n",
    "\t\t\tprint('threads %s, index %d, time-cost %f min'%(name,ii,(time()-t1)/60))\n",
    "\t\tif ii % 1000 == 0:\n",
    "\t\t\tjoblib.dump([ii,width,height],DATA_DIR+'raw_data/test_size_temp_{}.pkl'.format(name))\n",
    "\ttest_file['width']=width\n",
    "\ttest_file['height'] = height\n",
    "\tprint(name,'test shape',test_file.shape) #153730\n",
    "\n",
    "\ttest_file.to_csv(DATA_DIR+'raw_data/test_file_orig_{}.csv'.format(name),index=False)\n",
    "\n",
    "def get_test_size_multi_thread(thread_num=1):\n",
    "\ttest_file = pd.read_csv(DATA_DIR+'test_file.csv')\n",
    "\ttest_file['small_width']=test_file['width']\n",
    "\ttest_file['small_height'] = test_file['height']\n",
    "\tchunk=math.ceil(len(test_file)/thread_num)\n",
    "\tthread_list=[]\n",
    "\tfor ii in range(thread_num):\n",
    "\t\tsup_file=test_file.iloc[ii*chunk:(ii+1)*chunk]\n",
    "\t\tthr=threading.Thread(target=get_test_orig_size_split,args=(sup_file,ii))\n",
    "\t\tthread_list.append(thr)\n",
    "\tfor t in thread_list:\n",
    "\t\tt.setDaemon(True)\n",
    "\t\tt.start()\n",
    "\tfor t in thread_list:\n",
    "\t\tt.join()\n",
    "\n",
    "def merge_test_size_file():\n",
    "\tdata=pd.DataFrame()\n",
    "\tfor name in range(10):\n",
    "\t\tdata_path=DATA_DIR + 'raw_data/test_file_orig_{}.csv'.format(str(name))\n",
    "\t\ttemp=pd.read_csv(data_path)\n",
    "\t\tdata=pd.concat([data,temp])\n",
    "\t\tprint(name,data.shape)\n",
    "\n",
    "\tdata.to_csv(DATA_DIR + 'raw_data/test_file.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe59e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def prepare_data(CCT=True,iNat=True):\\n\\tif CCT:\\n\\t\\trewrite_train_data_json('CCT')\\n\\tif iNat:\\n\\t\\trewrite_train_data_json('iNat')\\n\\n\\tsplit_train_dev(CCT=CCT,iNat=iNat)\\n\\tsave_test()\";\n",
       "                var nbb_formatted_code = \"def prepare_data(CCT=True, iNat=True):\\n    if CCT:\\n        rewrite_train_data_json(\\\"CCT\\\")\\n    if iNat:\\n        rewrite_train_data_json(\\\"iNat\\\")\\n\\n    split_train_dev(CCT=CCT, iNat=iNat)\\n    save_test()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_data(CCT=True,iNat=True):\n",
    "\tif CCT:\n",
    "\t\trewrite_train_data_json('CCT')\n",
    "\tif iNat:\n",
    "\t\trewrite_train_data_json('iNat')\n",
    "\n",
    "\tsplit_train_dev(CCT=CCT,iNat=iNat)\n",
    "\tsave_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66a45df5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of  data: CCT 196157\n",
      "len of  data: iNat 25263\n",
      "use CCT data (196157, 9)\n",
      "use iNat data (25263, 9)\n",
      "train shape (221420, 9)\n",
      "category ratio for train data:\n",
      "0 130764 0.6074559264162777\n",
      "1 11115 0.051634032471604766\n",
      "2 22 0.00010219961442872738\n",
      "3 8001 0.03716814159292035\n",
      "4 2224 0.01033145193134044\n",
      "5 3361 0.015613313822497851\n",
      "6 8 3.7163496155900866e-05\n",
      "7 423 0.0019650198592432583\n",
      "8 8289 0.038506027454532785\n",
      "9 250 0.001161359254871902\n",
      "10 2247 0.010438296982788656\n",
      "11 8578 0.0398485587531647\n",
      "12 880 0.004087984577149095\n",
      "13 9668 0.044912085104406196\n",
      "14 1948 0.00904931131396186\n",
      "15 36 0.0001672357327015539\n",
      "16 6128 0.028467238055420063\n",
      "17 4927 0.022888068195015446\n",
      "18 3005 0.013959538243560263\n",
      "19 12766 0.05930364899077881\n",
      "20 307 0.0014261491649826957\n",
      "21 142 0.0006596520567672404\n",
      "22 176 0.000817596915429819\n",
      "category ratio for dev data:\n",
      "0 693 0.11259138911454103\n",
      "1 0 0.0\n",
      "2 0 0.0\n",
      "3 14 0.002274573517465475\n",
      "4 45 0.007311129163281885\n",
      "5 0 0.0\n",
      "6 0 0.0\n",
      "7 0 0.0\n",
      "8 566 0.09195775792038993\n",
      "9 0 0.0\n",
      "10 0 0.0\n",
      "11 873 0.14183590576766855\n",
      "12 0 0.0\n",
      "13 1464 0.237855402112104\n",
      "14 111 0.01803411860276198\n",
      "15 0 0.0\n",
      "16 999 0.16230706742485784\n",
      "17 21 0.003411860276198213\n",
      "18 30 0.00487408610885459\n",
      "19 1339 0.21754670999187653\n",
      "20 0 0.0\n",
      "21 0 0.0\n",
      "22 0 0.0\n",
      "test shape (153730, 9)\n"
     ]
    }
   ],
   "source": [
    "prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0074d75-b220-49ff-9231-915dbf8d69e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Detect using faster-RCNN\n",
    "\n",
    "Từ train_file.csv tạo ở bước prepare data lấy ra những ảnh thuộc dataset nào (CTT/iNat), lấy các thuộc tính: file_name, id, width\n",
    "\n",
    ".p là một model, `img2det[img_id][iBox=0]` => tức là lấy box của image có id là img_id\n",
    "\n",
    "Một image khi cropp ở hàm crop_image có thể fail khi:\n",
    "\n",
    "1. Đọc path không có file đó\n",
    "\n",
    "2. Image không có trong model\n",
    "\n",
    "3. Crop xong thì hình rỗng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f089f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"TRAIN_DATASET={'CCT':'iWildCam_2019_CCT','iNat':'iWildCam_2019_iNat_Idaho','IDFG':'iWildCam_IDFG'} #_images_small\\nDATA_DIR='./data/'\\nANNOTATION_DIR =DATA_DIR+ 'iWildCam_2019_Annotations/'\\n\\nbbox_detect_dir='data/bbox/'\";\n",
       "                var nbb_formatted_code = \"TRAIN_DATASET = {\\n    \\\"CCT\\\": \\\"iWildCam_2019_CCT\\\",\\n    \\\"iNat\\\": \\\"iWildCam_2019_iNat_Idaho\\\",\\n    \\\"IDFG\\\": \\\"iWildCam_IDFG\\\",\\n}  # _images_small\\nDATA_DIR = \\\"./data/\\\"\\nANNOTATION_DIR = DATA_DIR + \\\"iWildCam_2019_Annotations/\\\"\\n\\nbbox_detect_dir = \\\"data/bbox/\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_DATASET={'CCT':'iWildCam_2019_CCT','iNat':'iWildCam_2019_iNat_Idaho','IDFG':'iWildCam_IDFG'} #_images_small\n",
    "DATA_DIR='./data/'\n",
    "ANNOTATION_DIR =DATA_DIR+ 'iWildCam_2019_Annotations/'\n",
    "\n",
    "bbox_detect_dir='data/bbox/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e3eb015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"def crop_image(img_names,ws,ids,img2det,bbox_detect_dir):\\n\\tprint('images num:',len(img_names))\\n\\tprint('detection num:', len(img2det))\\n\\tt1=time()\\n\\tmiss=0\\n\\tfor ii in range(len(img_names)):\\n\\t\\tif ii%5000==0:\\n\\t\\t\\tprint('processing image',ii,(time()-t1)/(5000-1))\\n\\t\\t\\tt1 = time()\\n\\t\\timg_file = img_names[ii]\\n\\t\\tif os.path.exists(bbox_detect_dir + 'bbox_temp/' + img_file):\\n\\t\\t\\tcontinue\\n\\t\\tdirs = img_file.split('/')\\n\\t\\tfor jj in range(len(dirs)):\\n\\t\\t\\tnow_dir = '/'.join(dirs[:jj])\\n\\t\\t\\ttemp_dir = bbox_detect_dir + 'bbox_temp/' + now_dir\\n\\t\\t\\tif not os.path.exists(temp_dir):\\n\\t\\t\\t\\tos.mkdir(temp_dir)\\n\\t\\t\\tcrop_dir = bbox_detect_dir + 'cropped_image/' + now_dir\\n\\t\\t\\tif not os.path.exists(crop_dir):\\n\\t\\t\\t\\tos.mkdir(crop_dir)\\n\\t\\timg_id = ids[ii]\\n\\t\\timage = cv2.imread(DATA_DIR+img_file)\\n\\t\\tif image is None:\\n\\t\\t\\tmiss+=1\\n\\t\\t\\twith open(bbox_detect_dir + 'failed_images.txt','a') as f:\\n\\t\\t\\t\\tf.write(img_file+'\\\\n')\\n# \\t\\t\\tcv2.imwrite(bbox_detect_dir + 'cropped_image/' + img_file,np.array([0]))\\n\\t\\t\\tcontinue\\n\\t\\tiBox = 0\\n\\t\\ttry:\\n\\t\\t\\tbox = img2det[img_id][iBox]\\n\\t\\texcept KeyError as e:\\n\\t\\t\\tmiss+=1\\n\\t\\t\\twith open(bbox_detect_dir + 'failed_images.txt','a') as f:\\n\\t\\t\\t\\tf.write(img_file+'\\\\n')\\n\\t\\t#\\twith open(bbox_detect_dir+'bug_img/img_list.txt','a') as f:\\n\\t\\t#\\t\\tf.write(img_file+'\\\\t'+img_id+'\\\\n')\\n\\t\\t\\tcontinue\\n            \\n\\n\\t\\timageWidth = image.shape[1]\\n\\n\\t\\tratio = imageWidth / ws[ii]\\n\\t\\tbox_new = [x * ratio for x in box]\\n\\t\\tbuffer_scale=0.2\\n\\t\\tww = max(0, int((box_new[3] - box_new[1]) * buffer_scale))\\n\\t\\thh = max(0, int((box_new[2] - box_new[0]) * buffer_scale))\\n\\n\\t\\ttopRel = int(max(0, box_new[0] - hh))\\n\\t\\tleftRel = int(max(0, box_new[1] - ww))\\n\\t\\tbottomRel = int(box_new[2] + hh)\\n\\t\\trightRel = int(box_new[3] + ww)\\n\\n\\t\\tcropped = image.copy()[leftRel:rightRel, topRel:bottomRel] #.copy()\\n\\t\\tif cropped.size == 0:\\n\\t\\t\\tmiss+=1\\n\\t\\t\\twith open(bbox_detect_dir + 'failed_images.txt','a') as f:\\n\\t\\t\\t\\tf.write(img_file+'\\\\n')\\n# \\t\\t\\tcv2.imwrite(bbox_detect_dir + 'cropped_image/' + img_file,np.array([0]))\\n\\t\\telse: \\n\\t\\t\\tcv2.imwrite(bbox_detect_dir + 'cropped_image/' + img_file,cropped)\\n\\n\\n\\t\\t#img_det = cv2.rectangle(image.copy(),(topRel, leftRel), (bottomRel, rightRel), (0, 255, 0), 3)\\n\\t\\t#cv2.imwrite(bbox_detect_dir + 'bbox_temp/' + img_file, img_det)\\n\\tprint('all miss data',miss)\";\n",
       "                var nbb_formatted_code = \"def crop_image(img_names, ws, ids, img2det, bbox_detect_dir):\\n    print(\\\"images num:\\\", len(img_names))\\n    print(\\\"detection num:\\\", len(img2det))\\n    t1 = time()\\n    miss = 0\\n    for ii in range(len(img_names)):\\n        if ii % 5000 == 0:\\n            print(\\\"processing image\\\", ii, (time() - t1) / (5000 - 1))\\n            t1 = time()\\n        img_file = img_names[ii]\\n        if os.path.exists(bbox_detect_dir + \\\"bbox_temp/\\\" + img_file):\\n            continue\\n        dirs = img_file.split(\\\"/\\\")\\n        for jj in range(len(dirs)):\\n            now_dir = \\\"/\\\".join(dirs[:jj])\\n            temp_dir = bbox_detect_dir + \\\"bbox_temp/\\\" + now_dir\\n            if not os.path.exists(temp_dir):\\n                os.mkdir(temp_dir)\\n            crop_dir = bbox_detect_dir + \\\"cropped_image/\\\" + now_dir\\n            if not os.path.exists(crop_dir):\\n                os.mkdir(crop_dir)\\n        img_id = ids[ii]\\n        image = cv2.imread(DATA_DIR + img_file)\\n        if image is None:\\n            miss += 1\\n            with open(bbox_detect_dir + \\\"failed_images.txt\\\", \\\"a\\\") as f:\\n                f.write(img_file + \\\"\\\\n\\\")\\n            # \\t\\t\\tcv2.imwrite(bbox_detect_dir + 'cropped_image/' + img_file,np.array([0]))\\n            continue\\n        iBox = 0\\n        try:\\n            box = img2det[img_id][iBox]\\n        except KeyError as e:\\n            miss += 1\\n            with open(bbox_detect_dir + \\\"failed_images.txt\\\", \\\"a\\\") as f:\\n                f.write(img_file + \\\"\\\\n\\\")\\n            # \\twith open(bbox_detect_dir+'bug_img/img_list.txt','a') as f:\\n            # \\t\\tf.write(img_file+'\\\\t'+img_id+'\\\\n')\\n            continue\\n\\n        imageWidth = image.shape[1]\\n\\n        ratio = imageWidth / ws[ii]\\n        box_new = [x * ratio for x in box]\\n        buffer_scale = 0.2\\n        ww = max(0, int((box_new[3] - box_new[1]) * buffer_scale))\\n        hh = max(0, int((box_new[2] - box_new[0]) * buffer_scale))\\n\\n        topRel = int(max(0, box_new[0] - hh))\\n        leftRel = int(max(0, box_new[1] - ww))\\n        bottomRel = int(box_new[2] + hh)\\n        rightRel = int(box_new[3] + ww)\\n\\n        cropped = image.copy()[leftRel:rightRel, topRel:bottomRel]  # .copy()\\n        if cropped.size == 0:\\n            miss += 1\\n            with open(bbox_detect_dir + \\\"failed_images.txt\\\", \\\"a\\\") as f:\\n                f.write(img_file + \\\"\\\\n\\\")\\n        # \\t\\t\\tcv2.imwrite(bbox_detect_dir + 'cropped_image/' + img_file,np.array([0]))\\n        else:\\n            cv2.imwrite(bbox_detect_dir + \\\"cropped_image/\\\" + img_file, cropped)\\n\\n        # img_det = cv2.rectangle(image.copy(),(topRel, leftRel), (bottomRel, rightRel), (0, 255, 0), 3)\\n        # cv2.imwrite(bbox_detect_dir + 'bbox_temp/' + img_file, img_det)\\n    print(\\\"all miss data\\\", miss)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def crop_image(img_names,ws,ids,img2det,bbox_detect_dir):\n",
    "\tprint('images num:',len(img_names))\n",
    "\tprint('detection num:', len(img2det))\n",
    "\tt1=time()\n",
    "\tmiss=0\n",
    "\tzero=0\n",
    "\tfor ii in range(len(img_names)):\n",
    "\t\tif ii%5000==0:\n",
    "\t\t\tprint('processing image',ii,(time()-t1)/(5000-1))\n",
    "\t\t\tt1 = time()\n",
    "\t\timg_file = img_names[ii]\n",
    "\t\tif os.path.exists(bbox_detect_dir + 'bbox_temp/' + img_file):\n",
    "\t\t\tcontinue\n",
    "\t\tdirs = img_file.split('/')\n",
    "\t\tfor jj in range(len(dirs)):\n",
    "\t\t\tnow_dir = '/'.join(dirs[:jj])\n",
    "\t\t\ttemp_dir = bbox_detect_dir + 'bbox_temp/' + now_dir\n",
    "\t\t\tif not os.path.exists(temp_dir):\n",
    "\t\t\t\tos.mkdir(temp_dir)\n",
    "\t\t\tcrop_dir = bbox_detect_dir + 'cropped_image/' + now_dir\n",
    "\t\t\tif not os.path.exists(crop_dir):\n",
    "\t\t\t\tos.mkdir(crop_dir)\n",
    "\t\timg_id = ids[ii]\n",
    "\t\timage = cv2.imread(DATA_DIR+img_file)\n",
    "\t\tif image is None:\n",
    "\t\t\tmiss+=1\n",
    "\t\t\twith open(bbox_detect_dir + 'failed_images.txt','a') as f:\n",
    "\t\t\t\tf.write(img_file+'\\n')\n",
    "# \t\t\tcv2.imwrite(bbox_detect_dir + 'cropped_image/' + img_file,np.array([0]))\n",
    "\t\t\tcontinue\n",
    "\t\tiBox = 0\n",
    "\t\ttry:\n",
    "\t\t\tbox = img2det[img_id][iBox]\n",
    "\t\texcept KeyError as e:\n",
    "\t\t\tmiss+=1\n",
    "\t\t\twith open(bbox_detect_dir + 'failed_images.txt','a') as f:\n",
    "\t\t\t\tf.write(img_file+'\\n')\n",
    "\t\t#\twith open(bbox_detect_dir+'bug_img/img_list.txt','a') as f:\n",
    "\t\t#\t\tf.write(img_file+'\\t'+img_id+'\\n')\n",
    "\t\t\tcontinue\n",
    "            \n",
    "\n",
    "\t\timageWidth = image.shape[1]\n",
    "\n",
    "\t\tratio = imageWidth / ws[ii]\n",
    "\t\tbox_new = [x * ratio for x in box]\n",
    "\t\tbuffer_scale=0.2\n",
    "\t\tww = max(0, int((box_new[3] - box_new[1]) * buffer_scale))\n",
    "\t\thh = max(0, int((box_new[2] - box_new[0]) * buffer_scale))\n",
    "\n",
    "\t\ttopRel = int(max(0, box_new[0] - hh))\n",
    "\t\tleftRel = int(max(0, box_new[1] - ww))\n",
    "\t\tbottomRel = int(box_new[2] + hh)\n",
    "\t\trightRel = int(box_new[3] + ww)\n",
    "\n",
    "\t\tcropped = image.copy()[leftRel:rightRel, topRel:bottomRel] #.copy()\n",
    "\t\tif cropped.size == 0:\n",
    "\t\t\tmiss+=1\n",
    "\t\t\twith open(bbox_detect_dir + 'zero_images.txt','a') as f:\n",
    "\t\t\t\tf.write(img_file+'\\n')\n",
    "\t\t\tcv2.imwrite(bbox_detect_dir + 'cropped_image/' + img_file,np.array([0]))\n",
    "\t\telse: \n",
    "\t\t\tcv2.imwrite(bbox_detect_dir + 'cropped_image/' + img_file,cropped)\n",
    "\n",
    "\n",
    "\t\t#img_det = cv2.rectangle(image.copy(),(topRel, leftRel), (bottomRel, rightRel), (0, 255, 0), 3)\n",
    "\t\t#cv2.imwrite(bbox_detect_dir + 'bbox_temp/' + img_file, img_det)\n",
    "\tprint('all miss data',miss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e78211c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"train_file=pd.read_csv(DATA_DIR+'train_file.csv')\\ndev_file = pd.read_csv(DATA_DIR + 'dev_file.csv')\\ndata_file=pd.concat([train_file,dev_file])\";\n",
       "                var nbb_formatted_code = \"train_file = pd.read_csv(DATA_DIR + \\\"train_file.csv\\\")\\ndev_file = pd.read_csv(DATA_DIR + \\\"dev_file.csv\\\")\\ndata_file = pd.concat([train_file, dev_file])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_file=pd.read_csv(DATA_DIR+'train_file.csv')\n",
    "dev_file = pd.read_csv(DATA_DIR + 'dev_file.csv')\n",
    "data_file=pd.concat([train_file,dev_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a315c6",
   "metadata": {},
   "source": [
    "## Detect CTT images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620eb7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"img2det = {}\\nwith open(bbox_detect_dir+'Detection_Results/CCT_Detection_Results_1.p', 'rb') as data_file:\\n        temp = pickle.load(data_file, encoding='iso-8859-1')\\nfor img, res in zip(temp['images'], temp['detections']):\\n    img2det[img] = res[:10]\\nwith open(bbox_detect_dir+'Detection_Results/CCT_Detection_Results_2.p', 'rb') as data_file:\\n    temp = pickle.load(data_file, encoding='iso-8859-1')\\nfor img, res in zip(temp['images'], temp['detections']):\\n    img2det[img] = res[:10]\";\n",
       "                var nbb_formatted_code = \"img2det = {}\\nwith open(\\n    bbox_detect_dir + \\\"Detection_Results/CCT_Detection_Results_1.p\\\", \\\"rb\\\"\\n) as data_file:\\n    temp = pickle.load(data_file, encoding=\\\"iso-8859-1\\\")\\nfor img, res in zip(temp[\\\"images\\\"], temp[\\\"detections\\\"]):\\n    img2det[img] = res[:10]\\nwith open(\\n    bbox_detect_dir + \\\"Detection_Results/CCT_Detection_Results_2.p\\\", \\\"rb\\\"\\n) as data_file:\\n    temp = pickle.load(data_file, encoding=\\\"iso-8859-1\\\")\\nfor img, res in zip(temp[\\\"images\\\"], temp[\\\"detections\\\"]):\\n    img2det[img] = res[:10]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img2det = {}\n",
    "with open(bbox_detect_dir+'Detection_Results/CCT_Detection_Results_1.p', 'rb') as data_file:\n",
    "        temp = pickle.load(data_file, encoding='iso-8859-1')\n",
    "for img, res in zip(temp['images'], temp['detections']):\n",
    "    img2det[img] = res[:10]\n",
    "with open(bbox_detect_dir+'Detection_Results/CCT_Detection_Results_2.p', 'rb') as data_file:\n",
    "    temp = pickle.load(data_file, encoding='iso-8859-1')\n",
    "for img, res in zip(temp['images'], temp['detections']):\n",
    "    img2det[img] = res[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b2e52a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images num: 196157\n",
      "detection num: 196015\n",
      "processing image 0 7.630920715393079e-10\n",
      "processing image 5000 0.01300697217919536\n",
      "processing image 10000 0.01302206542497159\n",
      "processing image 15000 0.012746658533137901\n",
      "processing image 20000 0.01308282834812507\n",
      "processing image 25000 0.013097462307860743\n",
      "processing image 30000 0.013287499275749315\n",
      "processing image 35000 0.013158846960279507\n",
      "processing image 40000 0.01316627723547334\n",
      "processing image 45000 0.013206293640625097\n",
      "processing image 50000 0.07300618062569729\n",
      "processing image 55000 0.012992729637999132\n",
      "processing image 60000 0.0730627785923243\n",
      "processing image 65000 0.013204239444461769\n",
      "processing image 70000 0.07301715980364958\n",
      "processing image 75000 0.0727845657632503\n",
      "processing image 80000 0.013417896162774424\n",
      "processing image 85000 0.07303460871465065\n",
      "processing image 90000 0.013554148064491438\n",
      "processing image 95000 0.07255127487670997\n",
      "processing image 100000 0.05893480217344738\n",
      "processing image 105000 0.013204147062627857\n",
      "processing image 110000 0.013604554302049985\n",
      "processing image 115000 0.01407057110083821\n",
      "processing image 120000 0.0141433790507949\n",
      "processing image 125000 0.016432429104000123\n",
      "processing image 130000 0.01696802025009189\n",
      "processing image 135000 0.01615321648123265\n",
      "processing image 140000 0.016327098456113954\n",
      "processing image 145000 0.017473892584684538\n",
      "processing image 150000 0.016923113426319907\n",
      "processing image 155000 0.016924833960474957\n",
      "processing image 160000 0.01739285215899381\n",
      "processing image 165000 0.016227932590607477\n",
      "processing image 170000 0.016953747375985817\n",
      "processing image 175000 0.018006758395136057\n",
      "processing image 180000 0.016413110665117032\n",
      "processing image 185000 0.016837225458244724\n",
      "processing image 190000 0.017916384542625077\n",
      "processing image 195000 0.01776136601297921\n",
      "all miss data 143\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"data_cct = data_file[data_file['dataset']=='CCT'].reset_index(drop=True)\\nimg_names = data_cct['file_name'].values\\nids = data_cct['id'].values\\nws = data_cct['width'].values\\ncrop_image(img_names, ws, ids, img2det, bbox_detect_dir)\";\n",
       "                var nbb_formatted_code = \"data_cct = data_file[data_file[\\\"dataset\\\"] == \\\"CCT\\\"].reset_index(drop=True)\\nimg_names = data_cct[\\\"file_name\\\"].values\\nids = data_cct[\\\"id\\\"].values\\nws = data_cct[\\\"width\\\"].values\\ncrop_image(img_names, ws, ids, img2det, bbox_detect_dir)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_cct = data_file[data_file['dataset']=='CCT'].reset_index(drop=True)\n",
    "img_names = data_cct['file_name'].values\n",
    "ids = data_cct['id'].values\n",
    "ws = data_cct['width'].values\n",
    "crop_image(img_names, ws, ids, img2det, bbox_detect_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484d53ca-c470-47c7-a02d-09640d25fb55",
   "metadata": {},
   "source": [
    "## Detect iNat images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab8e3c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"img2det = {}\\nwith open(bbox_detect_dir+'Detection_Results/iNat_Idaho_Detection_Results.p', 'rb') as data_file:\\n    temp = pickle.load(data_file, encoding='iso-8859-1')\\nfor img, res in zip(temp['images'], temp['detections']):\\n    img2det[img] = res[:10]\";\n",
       "                var nbb_formatted_code = \"img2det = {}\\nwith open(\\n    bbox_detect_dir + \\\"Detection_Results/iNat_Idaho_Detection_Results.p\\\", \\\"rb\\\"\\n) as data_file:\\n    temp = pickle.load(data_file, encoding=\\\"iso-8859-1\\\")\\nfor img, res in zip(temp[\\\"images\\\"], temp[\\\"detections\\\"]):\\n    img2det[img] = res[:10]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img2det = {}\n",
    "with open(bbox_detect_dir+'Detection_Results/iNat_Idaho_Detection_Results.p', 'rb') as data_file:\n",
    "    temp = pickle.load(data_file, encoding='iso-8859-1')\n",
    "for img, res in zip(temp['images'], temp['detections']):\n",
    "    img2det[img] = res[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f44997",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_inat = data_file[data_file['dataset']=='iNat'].reset_index(drop=True)\n",
    "img_names = data_inat['file_name'].values\n",
    "ids = data_inat['id'].values\n",
    "ws = data_inat['width'].values\n",
    "\n",
    "crop_image(img_names, ws, ids, img2det, bbox_detect_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a9fe7-e180-4ad7-848f-74ba779ed39c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Detect test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e62b6cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"img2det = {}\\nwith open(bbox_detect_dir + 'Detection_Results/IDFG_Detection_Results_1.p', 'rb') as data_file:\\n    temp = pickle.load(data_file, encoding='iso-8859-1')\\nfor img, res in zip(temp['images'], temp['detections']):\\n    img2det[img] = res[:10]\\nwith open(bbox_detect_dir + 'Detection_Results/IDFG_Detection_Results_2.p', 'rb') as data_file:\\n    temp = pickle.load(data_file, encoding='iso-8859-1')\\nfor img, res in zip(temp['images'], temp['detections']):\\n    img2det[img] = res[:10]\";\n",
       "                var nbb_formatted_code = \"img2det = {}\\nwith open(\\n    bbox_detect_dir + \\\"Detection_Results/IDFG_Detection_Results_1.p\\\", \\\"rb\\\"\\n) as data_file:\\n    temp = pickle.load(data_file, encoding=\\\"iso-8859-1\\\")\\nfor img, res in zip(temp[\\\"images\\\"], temp[\\\"detections\\\"]):\\n    img2det[img] = res[:10]\\nwith open(\\n    bbox_detect_dir + \\\"Detection_Results/IDFG_Detection_Results_2.p\\\", \\\"rb\\\"\\n) as data_file:\\n    temp = pickle.load(data_file, encoding=\\\"iso-8859-1\\\")\\nfor img, res in zip(temp[\\\"images\\\"], temp[\\\"detections\\\"]):\\n    img2det[img] = res[:10]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img2det = {}\n",
    "with open(bbox_detect_dir + 'Detection_Results/IDFG_Detection_Results_1.p', 'rb') as data_file:\n",
    "    temp = pickle.load(data_file, encoding='iso-8859-1')\n",
    "for img, res in zip(temp['images'], temp['detections']):\n",
    "    img2det[img] = res[:10]\n",
    "with open(bbox_detect_dir + 'Detection_Results/IDFG_Detection_Results_2.p', 'rb') as data_file:\n",
    "    temp = pickle.load(data_file, encoding='iso-8859-1')\n",
    "for img, res in zip(temp['images'], temp['detections']):\n",
    "    img2det[img] = res[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e34cc85e-6d76-40aa-87cf-57ade4cb48be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_file (153730, 9)\n",
      "images num: 153730\n",
      "detection num: 153730\n",
      "processing image 0 8.584785804817213e-10\n",
      "processing image 5000 0.016586746304338994\n",
      "processing image 10000 0.01679950028473102\n",
      "processing image 15000 0.015362671313941133\n",
      "processing image 20000 0.013955226014151195\n",
      "processing image 25000 0.01333584616627305\n",
      "processing image 30000 0.013068846402871273\n",
      "processing image 35000 0.01268192123570283\n",
      "processing image 40000 0.012757221444365167\n",
      "processing image 45000 0.013085560980833251\n",
      "processing image 50000 0.012729864164361192\n",
      "processing image 55000 0.011313419719771591\n",
      "processing image 60000 0.011091036423608574\n",
      "processing image 65000 0.01085279402338903\n",
      "processing image 70000 0.011412709921592473\n",
      "processing image 75000 0.011336010202070932\n",
      "processing image 80000 0.01114318623116408\n",
      "processing image 85000 0.010458720114307896\n",
      "processing image 90000 0.011944347249195322\n",
      "processing image 95000 0.011972561147742854\n",
      "processing image 100000 0.011561860177821697\n",
      "processing image 105000 0.01254592101128966\n",
      "processing image 110000 0.011748461895977218\n",
      "processing image 115000 0.011358069810754753\n",
      "processing image 120000 0.011713419086481481\n",
      "processing image 125000 0.012030616143293966\n",
      "processing image 130000 0.010798204848947085\n",
      "processing image 135000 0.010540248298912102\n",
      "processing image 140000 0.01209824947052704\n",
      "processing image 145000 0.012975617536761136\n",
      "processing image 150000 0.01327100298981305\n",
      "all miss data 147689\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"data_file=pd.read_csv(DATA_DIR+'test_file.csv')\\nprint('test_file',data_file.shape)\\n\\nimg_names = data_file['file_name'].values\\nids = data_file['id'].values\\nws = data_file['height'].values\\n\\ncrop_image(img_names, ws, ids, img2det, bbox_detect_dir)\";\n",
       "                var nbb_formatted_code = \"data_file = pd.read_csv(DATA_DIR + \\\"test_file.csv\\\")\\nprint(\\\"test_file\\\", data_file.shape)\\n\\nimg_names = data_file[\\\"file_name\\\"].values\\nids = data_file[\\\"id\\\"].values\\nws = data_file[\\\"height\\\"].values\\n\\ncrop_image(img_names, ws, ids, img2det, bbox_detect_dir)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_file=pd.read_csv(DATA_DIR+'test_file.csv')\n",
    "print('test_file',data_file.shape)\n",
    "\n",
    "img_names = data_file['file_name'].values\n",
    "ids = data_file['id'].values\n",
    "ws = data_file['height'].values\n",
    "\n",
    "crop_image(img_names, ws, ids, img2det, bbox_detect_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13f37d-4467-495c-a377-83809c9c17ba",
   "metadata": {},
   "source": [
    "# Get cropped successful\n",
    "\n",
    "Vào folder và lấy *file_name* rùi map với train test csv và xuất ra một train test csv mới trong */data/bbox/cropped-image*\n",
    "\n",
    "Phần train model cho việc classification thì sẽ lấy trong bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a57260-cf2d-479c-af09-ef0b88e8595f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def rewrite_cropped_csv():\\n\\tdef check_file(df,prefix_dir='bbox/cropped_image/',name='train'):\\n\\t\\tdf=df.reset_index(drop=True)\\n\\t\\tprint(name,df.shape)\\n\\t\\tnew_df=pd.DataFrame(data=None,columns=df.columns)\\n\\t\\tt1=time()\\n\\t\\tfile_names=df['file_name'].values\\n\\t\\tvalid_ind=[]\\n\\t\\tnew_width,new_height=[],[]\\n\\t\\tfor ii, file in enumerate(file_names):\\n\\t\\t\\tnew_path = DATA_DIR + prefix_dir + file\\n\\t\\t\\tif os.path.exists(new_path):\\n\\t\\t\\t\\ttry:\\n\\t\\t\\t\\t\\timg = cv2.imread(new_path)\\n\\t\\t\\t\\t\\tsh=img.shape\\n\\t\\t\\t\\t\\tnew_width.append(sh[1])\\n\\t\\t\\t\\t\\tnew_height.append(sh[0])\\n\\t\\t\\t\\t\\tvalid_ind.append(ii)\\n\\t\\t\\t\\texcept:\\n\\t\\t\\t\\t\\tcontinue\\n\\n\\t\\tnew_df = df.iloc[valid_ind]\\n\\t\\tnew_df['new_width']=new_width\\n\\t\\tnew_df['new_height'] = new_height\\n\\t\\tprint('new_df for:', name, new_df.shape)\\n\\t\\tnew_df.to_csv(DATA_DIR+prefix_dir+name+'.csv',index=False)\\n\\t\\treturn new_df\\n\\tprint('get train cropped csv')\\n\\ttrain = pd.read_csv(DATA_DIR+'train_file.csv')\\n\\tnew_train=check_file(train,name='train_file')\\n\\tprint('get dev cropped csv')\\n\\tdev = pd.read_csv(DATA_DIR+'dev_file.csv')\\n\\tnew_dev=check_file(dev,name='dev_file')\\n\\tprint('get test cropped csv')\\n\\ttest = pd.read_csv(DATA_DIR+'test_file.csv')\\n\\tnew_test=check_file(test,name='test_file')\";\n",
       "                var nbb_formatted_code = \"def rewrite_cropped_csv():\\n    def check_file(df, prefix_dir=\\\"bbox/cropped_image/\\\", name=\\\"train\\\"):\\n        df = df.reset_index(drop=True)\\n        print(name, df.shape)\\n        new_df = pd.DataFrame(data=None, columns=df.columns)\\n        t1 = time()\\n        file_names = df[\\\"file_name\\\"].values\\n        valid_ind = []\\n        new_width, new_height = [], []\\n        for ii, file in enumerate(file_names):\\n            new_path = DATA_DIR + prefix_dir + file\\n            if os.path.exists(new_path):\\n                try:\\n                    img = cv2.imread(new_path)\\n                    sh = img.shape\\n                    new_width.append(sh[1])\\n                    new_height.append(sh[0])\\n                    valid_ind.append(ii)\\n                except:\\n                    continue\\n\\n        new_df = df.iloc[valid_ind]\\n        new_df[\\\"new_width\\\"] = new_width\\n        new_df[\\\"new_height\\\"] = new_height\\n        print(\\\"new_df for:\\\", name, new_df.shape)\\n        new_df.to_csv(DATA_DIR + prefix_dir + name + \\\".csv\\\", index=False)\\n        return new_df\\n\\n    print(\\\"get train cropped csv\\\")\\n    train = pd.read_csv(DATA_DIR + \\\"train_file.csv\\\")\\n    new_train = check_file(train, name=\\\"train_file\\\")\\n    print(\\\"get dev cropped csv\\\")\\n    dev = pd.read_csv(DATA_DIR + \\\"dev_file.csv\\\")\\n    new_dev = check_file(dev, name=\\\"dev_file\\\")\\n    print(\\\"get test cropped csv\\\")\\n    test = pd.read_csv(DATA_DIR + \\\"test_file.csv\\\")\\n    new_test = check_file(test, name=\\\"test_file\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rewrite_cropped_csv():\n",
    "\tdef check_file(df,prefix_dir='bbox/cropped_image/',name='train'):\n",
    "\t\tdf=df.reset_index(drop=True)\n",
    "\t\tprint(name,df.shape)\n",
    "\t\tnew_df=pd.DataFrame(data=None,columns=df.columns)\n",
    "\t\tt1=time()\n",
    "\t\tfile_names=df['file_name'].values\n",
    "\t\tvalid_ind=[]\n",
    "\t\tnew_width,new_height=[],[]\n",
    "\t\tfor ii, file in enumerate(file_names):\n",
    "\t\t\tnew_path = DATA_DIR + prefix_dir + file\n",
    "\t\t\tif os.path.exists(new_path):\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\timg = cv2.imread(new_path)\n",
    "\t\t\t\t\tsh=img.shape\n",
    "\t\t\t\t\tnew_width.append(sh[1])\n",
    "\t\t\t\t\tnew_height.append(sh[0])\n",
    "\t\t\t\t\tvalid_ind.append(ii)\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\tnew_df = df.iloc[valid_ind]\n",
    "\t\tnew_df['new_width']=new_width\n",
    "\t\tnew_df['new_height'] = new_height\n",
    "\t\tprint('new_df for:', name, new_df.shape)\n",
    "\t\tnew_df.to_csv(DATA_DIR+prefix_dir+name+'.csv',index=False)\n",
    "\t\treturn new_df\n",
    "\tprint('get train cropped csv')\n",
    "\ttrain = pd.read_csv(DATA_DIR+'train_file.csv')\n",
    "\tnew_train=check_file(train,name='train_file')\n",
    "\tprint('get dev cropped csv')\n",
    "\tdev = pd.read_csv(DATA_DIR+'dev_file.csv')\n",
    "\tnew_dev=check_file(dev,name='dev_file')\n",
    "\tprint('get test cropped csv')\n",
    "\ttest = pd.read_csv(DATA_DIR+'test_file.csv')\n",
    "\tnew_test=check_file(test,name='test_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1708d11c-e4b2-4aae-bac3-5d57ba2dd8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train cropped csv\n",
      "train_file (215265, 9)\n",
      "new_df for: train_file (196332, 11)\n",
      "get dev cropped csv\n",
      "dev_file (6155, 9)\n",
      "new_df for: dev_file (6145, 11)\n",
      "get test cropped csv\n",
      "test_file (153730, 9)\n",
      "new_df for: test_file (6041, 11)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"rewrite_cropped_csv()\";\n",
       "                var nbb_formatted_code = \"rewrite_cropped_csv()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewrite_cropped_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca4bea-e3f6-4b6f-a0df-35526f11dcf2",
   "metadata": {},
   "source": [
    "# Get small (200)\n",
    "\n",
    "Chọn 200 dòng đầu, rùi get những dòng path có ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "829d2158-7678-458e-817b-67a1a9237894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from shutil import copy2\\n\\ndef rewrite_cropped_csv():\\n\\tdef check_file(df,prefix_dir='bbox/cropped_image/',name='train'):\\n\\t\\tdf=df.reset_index(drop=True)\\n\\t\\tprint(name,df.shape)\\n\\t\\tt1=time()\\n\\t\\tfile_names=df['file_name'].values\\n\\t\\tvalid_ind=[]\\n\\t\\tnew_width,new_height=[],[]\\n\\t\\tcount_successful = 0\\n\\t\\tfor ii, file in enumerate(file_names):\\n\\t\\t\\tnew_path = DATA_DIR + prefix_dir + file\\n\\t\\t\\tnew_copy_path = DATA_DIR + prefix_dir + 'small/' + file\\n\\t\\t\\tif os.path.exists(new_path):\\n\\t\\t\\t\\ttry:\\n\\t\\t\\t\\t\\timg = cv2.imread(new_path)\\n\\t\\t\\t\\t\\tsh=img.shape\\n\\t\\t\\t\\t\\tnew_width.append(sh[1])\\n\\t\\t\\t\\t\\tnew_height.append(sh[0])\\n\\t\\t\\t\\t\\tvalid_ind.append(ii)\\n\\t\\t\\t\\t\\tcount_successful += 1\\n\\t\\t\\t\\texcept:\\n\\t\\t\\t\\t\\tcontinue\\n\\t\\t\\t\\tos.makedirs(os.path.dirname(new_copy_path), exist_ok=True)\\n\\t\\t\\t\\tcopy2(new_path, new_copy_path)\\n\\t\\t\\tif(count_successful == 500):\\n\\t\\t\\t\\tbreak\\n\\t\\tnew_df = df.iloc[valid_ind]\\n\\t\\tnew_df['new_width']=new_width\\n\\t\\tnew_df['new_height'] = new_height\\n\\t\\tprint('new_df for:', name, new_df.shape)\\n\\t\\tnew_df.to_csv(DATA_DIR+prefix_dir+ 'small/'+name+'.csv',index=False)\\n\\t\\treturn new_df\\n# \\tprint('get train cropped csv')\\n# \\ttrain = pd.read_csv(DATA_DIR+'train_file.csv')\\n# \\tnew_train=check_file(train,name='train_file')\\n\\tprint('get dev cropped csv')\\n\\tdev = pd.read_csv(DATA_DIR+'dev_file.csv')\\n\\tnew_dev=check_file(dev,name='dev_file')\\n# \\tprint('get test cropped csv')\\n# \\ttest = pd.read_csv(DATA_DIR+'test_file.csv')\\n# \\tnew_test=check_file(test,name='test_file')\";\n",
       "                var nbb_formatted_code = \"from shutil import copy2\\n\\n\\ndef rewrite_cropped_csv():\\n    def check_file(df, prefix_dir=\\\"bbox/cropped_image/\\\", name=\\\"train\\\"):\\n        df = df.reset_index(drop=True)\\n        print(name, df.shape)\\n        t1 = time()\\n        file_names = df[\\\"file_name\\\"].values\\n        valid_ind = []\\n        new_width, new_height = [], []\\n        count_successful = 0\\n        for ii, file in enumerate(file_names):\\n            new_path = DATA_DIR + prefix_dir + file\\n            new_copy_path = DATA_DIR + prefix_dir + \\\"small/\\\" + file\\n            if os.path.exists(new_path):\\n                try:\\n                    img = cv2.imread(new_path)\\n                    sh = img.shape\\n                    new_width.append(sh[1])\\n                    new_height.append(sh[0])\\n                    valid_ind.append(ii)\\n                    count_successful += 1\\n                except:\\n                    continue\\n                os.makedirs(os.path.dirname(new_copy_path), exist_ok=True)\\n                copy2(new_path, new_copy_path)\\n            if count_successful == 500:\\n                break\\n        new_df = df.iloc[valid_ind]\\n        new_df[\\\"new_width\\\"] = new_width\\n        new_df[\\\"new_height\\\"] = new_height\\n        print(\\\"new_df for:\\\", name, new_df.shape)\\n        new_df.to_csv(DATA_DIR + prefix_dir + \\\"small/\\\" + name + \\\".csv\\\", index=False)\\n        return new_df\\n\\n    # \\tprint('get train cropped csv')\\n    # \\ttrain = pd.read_csv(DATA_DIR+'train_file.csv')\\n    # \\tnew_train=check_file(train,name='train_file')\\n    print(\\\"get dev cropped csv\\\")\\n    dev = pd.read_csv(DATA_DIR + \\\"dev_file.csv\\\")\\n    new_dev = check_file(dev, name=\\\"dev_file\\\")\\n\\n\\n# \\tprint('get test cropped csv')\\n# \\ttest = pd.read_csv(DATA_DIR+'test_file.csv')\\n# \\tnew_test=check_file(test,name='test_file')\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from shutil import copy2\n",
    "\n",
    "def rewrite_cropped_csv():\n",
    "\tdef check_file(df,prefix_dir='bbox/cropped_image/',name='train'):\n",
    "\t\tdf=df.reset_index(drop=True)\n",
    "\t\tprint(name,df.shape)\n",
    "\t\tt1=time()\n",
    "\t\tfile_names=df['file_name'].values\n",
    "\t\tvalid_ind=[]\n",
    "\t\tnew_width,new_height=[],[]\n",
    "\t\tcount_successful = 0\n",
    "\t\tfor ii, file in enumerate(file_names):\n",
    "\t\t\tnew_path = DATA_DIR + prefix_dir + file\n",
    "\t\t\tnew_copy_path = DATA_DIR + prefix_dir + 'small/' + file\n",
    "\t\t\tif os.path.exists(new_path):\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\timg = cv2.imread(new_path)\n",
    "\t\t\t\t\tsh=img.shape\n",
    "\t\t\t\t\tnew_width.append(sh[1])\n",
    "\t\t\t\t\tnew_height.append(sh[0])\n",
    "\t\t\t\t\tvalid_ind.append(ii)\n",
    "\t\t\t\t\tcount_successful += 1\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tos.makedirs(os.path.dirname(new_copy_path), exist_ok=True)\n",
    "\t\t\t\tcopy2(new_path, new_copy_path)\n",
    "\t\t\tif(count_successful == 500):\n",
    "\t\t\t\tbreak\n",
    "\t\tnew_df = df.iloc[valid_ind]\n",
    "\t\tnew_df['new_width']=new_width\n",
    "\t\tnew_df['new_height'] = new_height\n",
    "\t\tprint('new_df for:', name, new_df.shape)\n",
    "\t\tnew_df.to_csv(DATA_DIR+prefix_dir+ 'small/'+name+'.csv',index=False)\n",
    "\t\treturn new_df\n",
    "# \tprint('get train cropped csv')\n",
    "# \ttrain = pd.read_csv(DATA_DIR+'train_file.csv')\n",
    "# \tnew_train=check_file(train,name='train_file')\n",
    "\tprint('get dev cropped csv')\n",
    "\tdev = pd.read_csv(DATA_DIR+'dev_file.csv')\n",
    "\tnew_dev=check_file(dev,name='dev_file')\n",
    "# \tprint('get test cropped csv')\n",
    "# \ttest = pd.read_csv(DATA_DIR+'test_file.csv')\n",
    "# \tnew_test=check_file(test,name='test_file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3edabc5-1903-4607-8802-ea925d3f06d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get dev cropped csv\n",
      "dev_file (6155, 9)\n",
      "new_df for: dev_file (500, 11)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"rewrite_cropped_csv()\";\n",
       "                var nbb_formatted_code = \"rewrite_cropped_csv()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewrite_cropped_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eef870a5-da62-4661-830c-77472247be2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"os.path.exists('./data/bbox/cropped_image/test_images/0a9b5c84-2c1c-11e9-bcad-06f10d5896c4.jpg')\";\n",
       "                var nbb_formatted_code = \"os.path.exists(\\n    \\\"./data/bbox/cropped_image/test_images/0a9b5c84-2c1c-11e9-bcad-06f10d5896c4.jpg\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.path.exists('./data/bbox/cropped_image/test_images/0a9b5c84-2c1c-11e9-bcad-06f10d5896c4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0766b-22b2-4c84-8317-f83b4bea5f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
